{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "foreign-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import string\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# requires update to tensorflow 2.4\n",
    "# >>> conda activate PIC16B\n",
    "# >>> pip install tensorflow==2.4\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for embedding viz\n",
    "import plotly.express as px \n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dimensional-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/tcc_ceds_music.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decimal-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'artist_name', 'track_name', 'release_date', 'genre',\n",
       "       'lyrics', 'len', 'dating', 'violence', 'world/life', 'night/time',\n",
       "       'shake the audience', 'family/gospel', 'romantic', 'communication',\n",
       "       'obscene', 'music', 'movement/places', 'light/visual perceptions',\n",
       "       'family/spiritual', 'like/girls', 'sadness', 'feelings', 'danceability',\n",
       "       'loudness', 'acousticness', 'instrumentalness', 'valence', 'energy',\n",
       "       'topic', 'age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reduced-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalars = ['dating', \n",
    "           'violence', \n",
    "           'world/life', \n",
    "           'night/time',\n",
    "           'shake the audience',\n",
    "           'family/gospel', \n",
    "           'romantic', \n",
    "           'communication',\n",
    "           'obscene', \n",
    "           'music', \n",
    "           'movement/places', \n",
    "           'light/visual perceptions',\n",
    "           'family/spiritual', \n",
    "           'like/girls', \n",
    "           'sadness', \n",
    "           'feelings', \n",
    "           'danceability',\n",
    "           'loudness', \n",
    "           'acousticness', \n",
    "           'instrumentalness', \n",
    "           'valence', \n",
    "           'energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ordered-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"lyrics\" : df[\"lyrics\"],\n",
    "    \"scalars\": df[scalars],\n",
    "    \"genre\"  : df[\"genre\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fiscal-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for pipeline\n",
    "num_genres = len(df[\"genre\"].unique())\n",
    "size_vocabulary = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "quiet-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "\n",
    "lyrics_input = keras.Input(\n",
    "    shape = (None,), \n",
    "    name = \"lyrics\"\n",
    ")\n",
    "\n",
    "scalars_input = keras.Input(\n",
    "    shape = len(scalars), \n",
    "    name = \"scalars\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "immediate-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_features = layers.Embedding(size_vocabulary, 30)(lyrics_input)\n",
    "lyrics_features = layers.LSTM(128)(lyrics_features)\n",
    "\n",
    "merged = layers.concatenate([lyrics_features, scalars_input])\n",
    "\n",
    "hidden_1 = layers.Dense(128, name = \"hidden_1\")(merged)\n",
    "output = layers.Dense(num_genres)(hidden_1)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = [lyrics_input, scalars_input],\n",
    "    outputs = output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "organizational-separation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "lyrics (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 30)     60000       lyrics[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 128)          81408       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "scalars (InputLayer)            [(None, 22)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 150)          0           lstm_2[0][0]                     \n",
      "                                                                 scalars[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_1 (Dense)                (None, 128)          19328       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7)            903         hidden_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 161,639\n",
      "Trainable params: 161,639\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "corporate-patrick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-safety",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
