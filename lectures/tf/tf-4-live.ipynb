{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceramic-relevance",
   "metadata": {
    "id": "limiting-remove"
   },
   "source": [
    "# Mixed Data Features\n",
    "\n",
    "In previous lectures, we've used neural networks to perform \"basic\" classification, image classification, and text classification. In each of these, we used a single pipeline that we custom built for the data we needed to work with, usually enclosed within a `keras.models.Sequential()` model. This worked fine for those situations, but what happens when we have *multiple* complex data components that we would like to use in our models? For example, maybe we would like to do classification in a dataset containing both: \n",
    "\n",
    "1. Pictures (images) and captions (text). \n",
    "2. Descriptions (text) and timestamps (numbers). \n",
    "3. Article bodies (text) and titles (different text). \n",
    "\n",
    "Of course, it's possible to come up with various ad hoc ways to smoosh pieces of data together, but this isn't usually the right approach. A better thing to do is to create a more flexible model that accepts and appropriately processes different kinds of inputs. In this lecture, we'll learn how to do this. \n",
    "\n",
    "### Key Tools\n",
    "\n",
    "- Labeled data sets. \n",
    "- The Keras functional API (alternative to Sequential API). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-deputy",
   "metadata": {
    "id": "billion-print"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import string\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow import keras\n",
    "\n",
    "# requires update to tensorflow 2.4\n",
    "# >>> conda activate PIC16B\n",
    "# >>> pip install tensorflow==2.4\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for embedding viz\n",
    "import plotly.express as px \n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-swing",
   "metadata": {
    "id": "sunrise-accreditation"
   },
   "source": [
    "Our data set for this lecture contains various information about various musical tracks produced between the years 1950 and 2019. You can find it on Kaggle [here](https://www.kaggle.com/saurabhshahane/music-dataset-1950-to-2019). The data was originally published in the following data publication: \n",
    "\n",
    "> Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; França, Mardônio (2020), “Music Dataset: Lyrics and Metadata from 1950 to 2019”, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-rover",
   "metadata": {
    "id": "resident-persian"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/tcc_ceds_music.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-gauge",
   "metadata": {
    "id": "attractive-thing"
   },
   "source": [
    "Let's take a quick look: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-diabetes",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "lasting-baltimore",
    "outputId": "214ef96b-5db1-44b3-fe54-44cd2cd0377a"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-childhood",
   "metadata": {
    "id": "unavailable-heating"
   },
   "source": [
    "We have a number of columns here! We'll focus on a few subsets in particular: \n",
    "\n",
    "The `genre` describes the overall genre of the track. It has seven values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-draft",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "defensive-backing",
    "outputId": "4bc2037d-b963-4954-c09d-106b25c6f5a1"
   },
   "outputs": [],
   "source": [
    "df.groupby(\"genre\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-elizabeth",
   "metadata": {
    "id": "coral-doubt"
   },
   "source": [
    "There data also includes \n",
    "- The complete `lyrics` of the track (if it has any) \n",
    "- The normalized `age` of the track (1.0 corresponds to tracks released in 1950, 0.0 corresponds to more recent tracks)\n",
    "- A selection of columns that give the track numerical scores reflecting various attributes and topics, such as \"danceability,\" \"loudness,\" and \"acousticness.\" \n",
    "\n",
    "There are also other columns in the data, but these are the ones we're going to focus on for this analysis. We are going to subset things a bit: let's focus on only a few genres, and on only relatively recent tracks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-queue",
   "metadata": {
    "id": "reverse-winner"
   },
   "outputs": [],
   "source": [
    "df = df[df[\"release_date\"] > 2000]\n",
    "genres = [\"blues\", \"hip hop\", \"country\"]\n",
    "df = df[df[\"genre\"].apply(lambda x: x in genres)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-collaboration",
   "metadata": {
    "id": "impossible-weekly"
   },
   "source": [
    "Next, let's do a categorical encoding of the `genre` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-puppy",
   "metadata": {
    "id": "annual-seeking"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df[\"genre\"] = le.fit_transform(df[\"genre\"])\n",
    "num_genres = len(df[\"genre\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-raleigh",
   "metadata": {
    "id": "experienced-sunset"
   },
   "source": [
    "## Create a Dataset\n",
    "\n",
    "We're now ready to create a TensorFlow `Dataset`. This is going to be a little more involved than last time, because we need to distinguish between different kinds of model inputs. \n",
    "\n",
    "Here's a list of all the scalar \"score\" columns in the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-philosophy",
   "metadata": {
    "id": "minus-triangle"
   },
   "outputs": [],
   "source": [
    "scalars = ['dating', \n",
    "           'violence', \n",
    "           'world/life', \n",
    "           'night/time',\n",
    "           'shake the audience',\n",
    "           'family/gospel', \n",
    "           'romantic', \n",
    "           'communication',\n",
    "           'obscene', \n",
    "           'music', \n",
    "           'movement/places', \n",
    "           'light/visual perceptions',\n",
    "           'family/spiritual', \n",
    "           'like/girls', \n",
    "           'sadness', \n",
    "           'feelings', \n",
    "           'danceability',\n",
    "           'loudness', \n",
    "           'acousticness', \n",
    "           'instrumentalness', \n",
    "           'valence', \n",
    "           'energy']        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-alexandria",
   "metadata": {
    "id": "reasonable-symposium"
   },
   "source": [
    "Because we have multiple inputs, we are going to construct our `Dataset` from a tuple of dictionaries. The first dictionary is going to specify the different components in the predictor data, while the second dictionary is going to specify the different components of the target data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-signal",
   "metadata": {
    "id": "upper-carter"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "comparable-angle",
   "metadata": {
    "id": "valid-miami"
   },
   "source": [
    "Next, we are going to perform a train/test/validation split. For each of the three split `Datasets`, we are going to *batch* them into small chunks of data. This helps with training runtime later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-windsor",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ordered-density",
    "outputId": "1c6fdfa1-bfcf-4b56-b37b-8bfaccddaf31"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "inner-rebel",
   "metadata": {
    "id": "growing-democracy"
   },
   "source": [
    "Each of the numbers above should be multipled by the batch size to give the total number of rows in each `Dataset`. \n",
    "\n",
    "The code below sets up exactly the same text preprocessing that we did [last lecture](https://nbviewer.jupyter.org/github/PhilChodrow/PIC16B/blob/master/lectures/tf/tf-3.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-medicaid",
   "metadata": {
    "id": "minimal-function"
   },
   "outputs": [],
   "source": [
    "size_vocabulary = 2000\n",
    "\n",
    "def standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    no_punctuation = tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation),'')\n",
    "    return no_punctuation \n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=standardization,\n",
    "    max_tokens=size_vocabulary, # only consider this many words\n",
    "    output_mode='int',\n",
    "    output_sequence_length=500) \n",
    "\n",
    "vectorize_layer.adapt(train.map(lambda x, y: x[\"lyrics\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-hormone",
   "metadata": {
    "id": "stopped-scholar"
   },
   "source": [
    "## The Keras Functional API\n",
    "\n",
    "In previousl lectures, we used the `Sequential` API for constructing models. For example, we wrote code like this: \n",
    "\n",
    "```python\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_tokens, output_dim = 3),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(len(categories))]\n",
    ")\n",
    "```\n",
    "\n",
    "This model is designed to accept a single kind of input (in this case text) and spit out a single output. However, in our case we have two distinct *kinds* of input: the song lyrics and the scalar scores. It wouldn't really make much sense to pass the scalar scores through a text vectorization or embedding layer. For this reason, we need to move beyond the `Sequential` API and instead constructing our models using a somewhat more manual approach, referred to as the `Functional` API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-float",
   "metadata": {
    "id": "great-gambling"
   },
   "source": [
    "### Inputs\n",
    "\n",
    "Start by specifying the two kinds of `keras.Input` for our model. You should have one input for each qualitatively distinct \"kind\" of predictor data. All the parameters here are important: \n",
    "\n",
    "- `shape` should describe the shape of a single item of data. For example, the `lyrics` column contains just one entry for each song, so the shape is `(1,)` (a tuple of length 1). On the other hand, there are `len(scalars) = 22` distinct columns of scalar scores. \n",
    "- the `name` should be some descriptive name that you're able to remember for later. \n",
    "- The `dtype` specifies the kind of data contained in each of the input tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-respect",
   "metadata": {
    "id": "cooperative-confidence"
   },
   "outputs": [],
   "source": [
    "# inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-interface",
   "metadata": {
    "id": "chronic-carbon"
   },
   "source": [
    "## Hidden Layers\n",
    "\n",
    "First, let's write a pipeline for the lyrics. This pipeline is pretty much the same as the one we used earlier for text classification -- we're just building it differently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-venice",
   "metadata": {
    "id": "comprehensive-overall"
   },
   "outputs": [],
   "source": [
    "# layers for processing the lyrics, pretty much the same as from our lecture\n",
    "# on text classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-poster",
   "metadata": {
    "id": "accredited-canvas"
   },
   "source": [
    "Next, let's write a pipeline for the scalars. We don't need to do anything fancy with them, so instead of messing with `Embeddings` and the like, we're just going to pass them through a `Dense` layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-gothic",
   "metadata": {
    "id": "opposed-scene"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "consistent-arena",
   "metadata": {
    "id": "accurate-omega"
   },
   "source": [
    "Here's simultaneously the most important and most boring part of the whole model: we are going to `concatenate` the output of the `lyrics` pipeline with the output of the `scalar` pipeline: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-peeing",
   "metadata": {
    "id": "conscious-mapping"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-restoration",
   "metadata": {
    "id": "pleased-fighter"
   },
   "source": [
    "Finally, let's pass the consolidated set of computed features through a few more `Dense` layers. Remember that the very last `Dense` layer should have a number of outputs equal to the number of classes in the data. \n",
    "\n",
    "**Observe that the output layer has a name, and that this name matches the key corresponding to the target data in the `Datasets` we will pass to the model.** This is how TensorFlow knows which part of our data set to compare against the outputs! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-prairie",
   "metadata": {
    "id": "fleet-society"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "wrong-flash",
   "metadata": {
    "id": "cognitive-sleeve"
   },
   "source": [
    "So far, we haven't actually created a model yet -- just a bunch of interrelated layers. We create the model by specifying the input(s) and output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-attachment",
   "metadata": {
    "id": "accredited-publication"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "informed-herald",
   "metadata": {
    "id": "authentic-conversion"
   },
   "source": [
    "The model summary provides one good way to look at the structure of the model, but it can be difficult to read when there are multiple inputs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-genesis",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "homeless-terrain",
    "outputId": "14d43985-1a3b-47da-eaa5-f676fa256b26"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "guided-opinion",
   "metadata": {
    "id": "lined-blade"
   },
   "source": [
    "Something a bit more visually attractive can be obtained by using the `plot_model` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-bobby",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "id": "outdoor-prague",
    "outputId": "e865ded8-d1cc-4ba3-c2a2-3f5ada204528"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "manual-procurement",
   "metadata": {
    "id": "executed-capability"
   },
   "source": [
    "Now we're ready to train and evaluate our model as usual! As always, we need to compile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-sensitivity",
   "metadata": {
    "id": "reported-glass"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "heard-emphasis",
   "metadata": {
    "id": "distinct-premium"
   },
   "source": [
    "And now we train! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-certificate",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "developing-bread",
    "outputId": "4a0d5e74-0f8b-4e33-debb-4d0b91b9cc67"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-founder",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "fixed-questionnaire",
    "outputId": "654c119a-86a6-4bdc-8d3e-090d344979b4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "authentic-spiritual",
   "metadata": {
    "id": "cognitive-amateur"
   },
   "source": [
    "## Visualizing Embeddings\n",
    "\n",
    "As usual, it's fun to take a look at the embedding learned by our model. Provided that we gave our embedding layer a name, the same approach as last time works just fine: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-reynolds",
   "metadata": {
    "id": "blond-holly"
   },
   "outputs": [],
   "source": [
    "weights = model.get_layer('embedding').get_weights()[0] # get the weights from the embedding layer\n",
    "vocab = vectorize_layer.get_vocabulary()                # get the vocabulary from our data prep for later\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "weights = pca.fit_transform(weights)\n",
    "\n",
    "embedding_df = pd.DataFrame({\n",
    "    'word' : vocab, \n",
    "    'x0'   : weights[:,0],\n",
    "    'x1'   : weights[:,1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-ukraine",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "continuing-fluid",
    "outputId": "2e7b14de-fea6-473a-9351-5cdb07831322"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "fig = px.scatter(embedding_df, \n",
    "                 x = \"x0\", \n",
    "                 y = \"x1\", \n",
    "                 size = list(np.ones(len(embedding_df))),\n",
    "                 size_max = 2,\n",
    "                 hover_name = \"word\")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "music-scratch-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
