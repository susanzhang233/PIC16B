{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "canadian-active",
   "metadata": {},
   "source": [
    "# Text Classification and Word Embedding\n",
    "\n",
    "In this set of notes, we'll discuss the problem of *text classification*. Text classification is a common problem in which we aim to classify pieces of text into different categories. These categories might be about:\n",
    "\n",
    "- **Subject matter**: is this news article about news, fashion, finance?\n",
    "- **Emotional valence**: is this tweet happy or sad? Excited or calm? This particular class of questions is so important that it has its own name: *sentiment analysis.* \n",
    "- **Automated content moderation**: is this Facebook comment a possible instance of abuse or harassment? Is this Reddit thread promoting violence? Is this email spam? \n",
    "\n",
    "These are all very different kinds of questions, but many of the same techniques can be used. In these notes, we'll do a simple example of subject matter classification. In future notes, we'll also do some sentiment analysis. \n",
    "\n",
    "\n",
    "### Bias in Natural Language Processing\n",
    "\n",
    "Like all other machine learning algorithms, natural language algorithms naturally inherit the biases of both the data on which they are trained and the choices made by researchers in training the algorithms. A sub-theme of this set of lectures is the need to carefully check our model outputs so that we can understand the impact of each of these. \n",
    "\n",
    "#### Optional Review\n",
    "\n",
    "- [Term-document matrices](https://nbviewer.jupyter.org/github/PhilChodrow/PIC16A/blob/master/content/NLP/NLP_1.ipynb). \n",
    "- [Sentiment analysis](https://nbviewer.jupyter.org/github/PhilChodrow/PIC16A/blob/master/content/NLP/NLP_3.ipynb). \n",
    "\n",
    "#### Related Resources\n",
    "\n",
    "- This set of lecture notes is partially based on this [official tutorial](https://www.tensorflow.org/tutorials/keras/text_classification). \n",
    "\n",
    "#### Heads Up\n",
    "\n",
    "To run the code in this notebook, you will actually need to **update TensorFlow**. To do this, open up a terminal and type the following two lines: \n",
    "\n",
    "```bash\n",
    "conda activate PIC16B\n",
    "pip install tensorflow==2.4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import string\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "# requires update to tensorflow 2.4\n",
    "# >>> conda activate PIC16B\n",
    "# >>> pip install tensorflow==2.4\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for embedding viz\n",
    "import plotly.express as px \n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-moscow",
   "metadata": {},
   "source": [
    "For this example, we are going to use a data set containing headlines from a large number of different news articles on the website [HuffPost](https://www.huffpost.com/). I retrieved this data [from Kaggle](https://www.kaggle.com/rmisra/news-category-dataset). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/datasets/news/News_Category_Dataset_v2.json\"\n",
    "df  = pd.read_json(url, lines=True)\n",
    "df  = df[[\"category\", \"headline\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-nicaragua",
   "metadata": {},
   "source": [
    "There are over 200,000 headlines listed here, along with the category in which they appeared on the website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-agent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-tourism",
   "metadata": {},
   "source": [
    "Our task will be to teach an algorithm to classify headlines by predicting the category based on the text of the headline. \n",
    "\n",
    "Training a model on this much text data can require a lot of time, so we are going to simplify the problem a little bit, by reducing the number of categories. Let's take a look at which categories we have: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-inspiration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "floating-kelly",
   "metadata": {},
   "source": [
    "Some of these categories are a little odd:\n",
    "\n",
    "- \"Women\"? \n",
    "- \"Weird News\"? \n",
    "- What's the difference between \"Style,\" \"Style & Beauty,\" and \"Taste\"? ). \n",
    "- \"Parenting\" vs. \"Parents\"? \n",
    "- Etc?...\n",
    "\n",
    "Well, there are definitely some questions here! Let's just choose a few categories, and discard the rest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-layout",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "civilian-burner",
   "metadata": {},
   "source": [
    "Next, we'll use a `LabelEncoder` to transform the `category` column into integers. \n",
    "\n",
    "**Note**: I couldn't find a way that I was satisfied with to do this in TensorFlow, but if you know a smooth way, let me know! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-distributor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "discrete-router",
   "metadata": {},
   "source": [
    "Later, we'll be able to remember which integers correspond to which classes using the `classes_` attribute of the encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-cooperation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "attractive-programmer",
   "metadata": {},
   "source": [
    "We're left with a much smaller number of rows, which will be much easier to work with. \n",
    "\n",
    "#### So Far....\n",
    "\n",
    "...we have accessed our data, examined the categories available, and taken a subset of the data corresponding to just three categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-international",
   "metadata": {},
   "source": [
    "## TensorFlow Datasets\n",
    "\n",
    "Next, we are going create a TensorFlow `Dataset` from our data frame. While we often talk colloquially about \"data sets\", TensorFlow has a special `Dataset` class with a number of convenient capabilities. Use of `Dataset`s is generally optional, but can make it significantly easier to stay organized when writing data pipelines. The `Dataset` class also includes functionality for a wide-variety of data input scenarios, including situations in which the data should be read in chunks-at-a-time from disk. \n",
    "\n",
    "The `Dataset` class is useful for all kinds of problems, not just text classification problems. Learn more about it [here](https://www.tensorflow.org/guide/data).\n",
    "\n",
    "We'll make a dataset with the predictor data (the headline) and target data (the category) separated out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-steps",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-orientation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "substantial-capacity",
   "metadata": {},
   "source": [
    "Now we'll perform a train-test split. We'll also take out a small validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-delhi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-sucking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-myrtle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "organizational-chinese",
   "metadata": {},
   "source": [
    "#### So far....\n",
    "\n",
    "...we have created a special TensorFlow `Dataset` and split it into training, validation, and testing sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-christianity",
   "metadata": {},
   "source": [
    "## Standardization and Vectorization\n",
    "\n",
    "*Standardization* refers to the act of taking a some text that's \"messy\" in some way and making it less messy. Common standardizations include: \n",
    "\n",
    "- Removing capitals. \n",
    "- Removing punctuation. \n",
    "- Removing HTML elements or other non-semantic content. \n",
    "\n",
    "In this standardization, we convert all text to lowercase and remove punctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-pulse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "proof-leonard",
   "metadata": {},
   "source": [
    "*Vectorization* refers to the process of representing text as a vector (array, tensor). There are multiple ways to carry out vectorization. For example, forming a *term-document matrix*, as demonstrated in the optional review lecture notes, is one way to form vectors from text. Here, we'll use a different approach: we'll replace each word by its *frequency rank* in the data. For example, the headline\n",
    "\n",
    "> Poll: Penguins Best Bird\n",
    "\n",
    "might have representation \n",
    "\n",
    "```[708, 1567, 89, 632].```\n",
    "\n",
    "This means that \"poll\" is the 708th most common word in the data set, \"penguins\" is the 1567 most common word in the data set, and so on.  \n",
    "\n",
    "For technical details on how TensorFlow carries out the vectorization, check [the docs](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization). Note that we pass the standardization from above as an argument to the vectorization layer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-rochester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "later-draft",
   "metadata": {},
   "source": [
    "We need to *adapt* the vectorization layer to the headlines. In the adaptation process, the vectorization layer learns what words are common in the headlines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-timeline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "conscious-blackberry",
   "metadata": {},
   "source": [
    "Now we're ready to vectorize each of the data sets. To do so, we define a helper function that operates on our Datasets. Note that our Dataset consists of a bunch of tuples of the form (headline, category) for each data observation. Our helper function therefore accepts and returns two variables. \n",
    "\n",
    "**Note**: because we adapted the vectorization layer to the training data, not the validation or testing data, we aren't \"cheating\" by propagating information from the validation or testing data prior to the training step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-decade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "collect-grocery",
   "metadata": {},
   "source": [
    "Let's take a look at a vectorized piece of text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-august",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "twelve-thermal",
   "metadata": {},
   "source": [
    "#### So far...\n",
    "\n",
    "...we have finally prepared our data! We have represented each of our headlines as numerical vectors, which are something that TensorFlow is able to understand. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-method",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Phew, that was a lot of data preparation! That's kind of how it is in the world of machine learning: so much of the effort goes into ensuring that your data is correctly formatted and represented. \n",
    "\n",
    "Let's now construct a simple model out of some layers. This model is going to have a few new components. \n",
    "\n",
    "The most interesting of these, which we are going to come back to, is the `Embedding` layer. Because we're going to come back to it, let's give it a name! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-ranking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-wrapping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "detected-montana",
   "metadata": {},
   "source": [
    "Let's go ahead and fit our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-durham",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-namibia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "painful-poison",
   "metadata": {},
   "source": [
    "At this point, it would be appropriate to be somewhat disturbed -- can it really be correct that the validation accuracy is *higher* than the training accuracy? That doesn't seem right, does it? The reason this occurs is due to those `Dropout` layers in the model. What these layers do is disable (\"drop out\") a fixed percentage of the units in each layer, *but only during training.* This turns out to be a good way to reduce the risk of overfitting. Because the units are used during validation and testing, but not during training, it can happen that indeed the validation and testing scores can be higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-thomson",
   "metadata": {},
   "source": [
    "# Predictions on Unseen Data\n",
    "\n",
    "Let's check our model performance on unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-investing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-charles",
   "metadata": {},
   "source": [
    "Not bad! We're able to correctly classify the category of a given news headline on HuffPost 90% of the time, at least when we are choosing between the three categories that we selected earlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-packing",
   "metadata": {},
   "source": [
    "### So far...\n",
    "\n",
    "...we have trained our model and evaluated it on unseen data, obtaining reasonable results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-transaction",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "A *word embedding* refers to a representation of a word in a vector space. Each word is assigned an individual vector. The general aim of a word embedding is to create a representation such that words with related meanings are close to each other in a vector space, while words with different meanings are farther apart. One usually hopes for the *directions* connecting words to be meaningful as well. Here's a nice diagram illustrating some of the general concepts: \n",
    "\n",
    "![](https://miro.medium.com/max/1838/1*OEmWDt4eztOcm5pr2QbxfA.png)\n",
    "\n",
    "*Image credit: [Towards Data Science](https://towardsdatascience.com/creating-word-embeddings-coding-the-word2vec-algorithm-in-python-using-deep-learning-b337d0ba17a8)*\n",
    "\n",
    "Word embeddings are often produced as intermediate stages in many machine learning algorithms. In fact, we already made one -- it's the `Embedding` layer at the base of our model. Let's take a look at the embedding layer to see how our own model represents words in a vector space. \n",
    "\n",
    "We chose to create a 3-dimensional embedding when constructing our model. This is fine for today, but state-of-the-art embeddings will typically have a much higher number of dimensions.  For example, the [Embedding Projector demo](http://projector.tensorflow.org/) supplied by TensorFlow uses a default dimension of 200. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-brass",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-resistance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "annoying-credits",
   "metadata": {},
   "source": [
    "The collection of weights is 3-dimensional. For plotting in 2 dimensions, we have several choices for how to reduce the data to a 2d representation. A very simple and standard approach is our friend, principal component analysis (PCA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-manor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "perceived-timothy",
   "metadata": {},
   "source": [
    "Now we'll make a data frame from our results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-screen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "multiple-somerset",
   "metadata": {},
   "source": [
    "Ready to plot! Note that the embedding appear to be \"stretched out\" in three directions, with one direction corresponding to each of the three categories (tech, style, science). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-projector",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eastern-fifth",
   "metadata": {},
   "source": [
    "Cool, we made a word embedding! This embedding seems to have learned some reasonable associations. For example, we see that words like \"Mars\", \"NASA\", and \"space\" are relatively close to each other. So are \"Facebook\", \"Google\", and \"Apple\", as well as \"fashion\", \"dress\", and \"style.\"\n",
    "\n",
    "## Bias in Language Models\n",
    "\n",
    "Whenever we create a machine learning model that might conceivably have impact on the thoughts or actions of human beings, we have a responsibility to understand the limitations and biases of that model. Biases can enter into machine learning models through several routes, including the data used as well as choices made by the modeler along the way. For example, in our case: \n",
    "\n",
    "1. **Data**: we used data from a popular news source. \n",
    "2. **Modeler choice**: we only used data corresponding to a certain subset of labels. \n",
    "\n",
    "With these considerations in mind, let's see what kinds of words our model associates with female and male genders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-anderson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-swimming",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-industry",
   "metadata": {},
   "source": [
    "Our text classification model's word embedding is unambiguously sexist. \n",
    "\n",
    "- Words like \"hot\", \"sexy\", and \"shopping\" are more closely located to feminine words like \"she\", \"her\", and \"woman\".\n",
    "- Words like \"strong\", \"smart\", and \"thinking\" are more closely located to masculine words like \"he\", \"him\", and \"man\". \n",
    "\n",
    "Where did these biases come from? \n",
    "\n",
    "- The primary source is the data itself: HuffPost headlines in certain categories can be highly gendered, and the \"Style\" category is an example of this. \n",
    "- A secondary source is the choices that I made as a modeler. In particular, I intentionally chose categories that would emphasize biases in the data and make them easy to visualize. \n",
    "\n",
    "While I could have made different choices and obtained different results, this episode highlights a fundamental set of questions usually underexamined in contemporary machine learning: \n",
    "\n",
    "- What biases are built into my data source? \n",
    "- How do my choices about which data to use influence the biases present in my model? \n",
    "\n",
    "For more on the topic of bias in language models, you may wish to read the now-infamous paper by Emily Bender, Angelina McMillan-Major, Timnt Gebru, and \"Shmargret Shmitchell\" (Margret Mitchell), \"[On the Dangers of Stochastic Parrots](https://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf).\" This is the paper that ultimately led to the firing of the final two authors by Google in late 2020 and early 2021. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PIC16B] *",
   "language": "python",
   "name": "conda-env-PIC16B-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
